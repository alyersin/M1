# ComparaÈ›ie: Implementarea Mea vs. eigenfaces_lab.py

## ğŸ” AnalizÄƒ ComparativÄƒ

### 1. **Metoda de Calcul a Eigenfaces** âŒ DIFERENÈšÄ‚ MAJORÄ‚

#### FiÈ™ierul de referinÈ›Äƒ (`eigenfaces_lab.py`):
- **FoloseÈ™te algoritmul Lanczos** (linia 57-98)
- MetodÄƒ iterativÄƒ pentru calcularea vectorilor proprii
- CalculeazÄƒ eigenfaces direct prin iteraÈ›ii

```python
def train_lanczos(train_mat, k):
    # Algoritm Lanczos pentru calcularea eigenfaces
    # CalculeazÄƒ q[:, 2:] care devine eigenfaces
```

#### Implementarea mea (`algoritmi/eigenfaces.py`):
- **FoloseÈ™te SVD, PCA neoptimizatÄƒ (C), sau PCA optimizatÄƒ (L)**
- Nu foloseÈ™te Lanczos
- **LIPSEÈ˜TE:** Varianta Lanczos

**Concluzie:** Trebuie sÄƒ adaug metoda Lanczos pentru a corespunde cu referinÈ›a.

---

### 2. **ReprezentanÈ›i de ClasÄƒ** âœ… SIMILAR

#### FiÈ™ierul de referinÈ›Äƒ:
```python
def get_class_representatives(train_mat, train_lbls, method='mean'):
    # CalculeazÄƒ media pozelor pentru fiecare persoanÄƒ
    rep = np.mean(person_imgs, axis=1)
```

#### Implementarea mea:
```python
def MATRICE_REPREZENTANTI(A, etichete_antrenare, nr_persoane, metoda='media'):
    # SuportÄƒ 'media' È™i 'aleatorie'
    RC[:, persoana] = np.mean(poze_persoana, axis=1)
```

**Concluzie:** âœ… Corect - ambele calculeazÄƒ media pozelor pentru reprezentanÈ›i.

---

### 3. **ProiecÈ›ie** âš ï¸ VERIFICARE NECESARÄ‚

#### FiÈ™ierul de referinÈ›Äƒ:
```python
def project(data, mean_face, eigenfaces):
    data_centered = data - mean_face
    return np.dot(eigenfaces.T, data_centered)
```
- `eigenfaces` este (m Ã— k) unde m = nrPixeli, k = numÄƒr eigenfaces
- ProiecÈ›ia: `eigenfaces.T @ data_centered` = (k Ã— m) @ (m Ã— 1) = (k Ã— 1)

#### Implementarea mea:
```python
# Ãn PREPROCESARE_EIGENFACES_CLASIC:
proiectii = A_centrat.T @ HQPB  # (nrPoze Ã— m) @ (m Ã— k) = (nrPoze Ã— k)

# Ãn ALG_EIGENFACES_CLASIC:
pr_test = poza_test_centrat @ HQPB  # (m,) @ (m Ã— k) = (k,)
```
- `HQPB` este (m Ã— k)
- ProiecÈ›ia: `data.T @ HQPB` = (1 Ã— m) @ (m Ã— k) = (1 Ã— k)

**Verificare matematicÄƒ:**
- DacÄƒ `eigenfaces = HQPB.T`, atunci:
  - `eigenfaces.T @ data = HQPB @ data` (k Ã— m @ m Ã— 1 = k Ã— 1)
  - Dar eu fac `data.T @ HQPB` (1 Ã— m @ m Ã— k = 1 Ã— k)
  - Rezultatul este transpusa: `(data.T @ HQPB).T = HQPB.T @ data = eigenfaces.T @ data`
  - **ECHIVALENT!** âœ…

**Concluzie:** âœ… Corect - proiecÈ›iile sunt echivalente (doar transpusa).

---

### 4. **DistanÈ›e** âœ… SIMILAR

#### FiÈ™ierul de referinÈ›Äƒ:
```python
def dist_metric(v1, v2, norm):
    if norm == 'manhattan': return la.norm(v1 - v2, 1)
    if norm == 'euclidean': return la.norm(v1 - v2, 2)
    if norm == np.inf: return la.norm(v1 - v2, np.inf)
    if norm == 'cos': return 1 - np.dot(v1, v2) / (la.norm(v1) * la.norm(v2))
```

#### Implementarea mea:
```python
# Ãn utils/distante.py - CALC_DISTANTA_NORMA()
# CalculeazÄƒ aceleaÈ™i norme
```

**Concluzie:** âœ… Corect - ambele calculeazÄƒ aceleaÈ™i distanÈ›e.

---

### 5. **Predictie (NN)** âœ… SIMILAR

#### FiÈ™ierul de referinÈ›Äƒ:
```python
def predict(test_proj, train_proj, train_lbls, norm):
    # NN pe proiecÈ›ii
    for i in range(train_proj.shape[1]):
        d = dist_metric(test_proj, train_proj[:, i], norm)
        if d < best_dist:
            best_dist = d
            best_lbl = train_lbls[i]
```

#### Implementarea mea:
```python
def ALG_EIGENFACES_CLASIC(...):
    # NN pe proiecÈ›ii
    for i in range(nr_poze_antrenare):
        distante[i] = CALC_DISTANTA_NORMA(proiectii[i, :], pr_test, norma)
    pozitia = np.argmin(distante)
```

**Concluzie:** âœ… Corect - ambele folosesc NN pe proiecÈ›ii.

---

### 6. **Structura Datelor** âš ï¸ DIFERENÈšÄ‚

#### FiÈ™ierul de referinÈ›Äƒ:
- `training_matrix` este (m Ã— n) unde m = nrPixeli, n = nrPoze
- `eigenfaces` este (m Ã— k)
- `train_proj` este (k Ã— n) - **TRANSPUSÄ‚!**

#### Implementarea mea:
- `A` este (m Ã— n) - âœ… ACELAÈ˜I
- `HQPB` este (m Ã— k) - âœ… ACELAÈ˜I
- `proiectii` este (n Ã— k) - **TRANSPUSÄ‚ faÈ›Äƒ de referinÈ›Äƒ!**

**Impact:** Nu afecteazÄƒ funcÈ›ionalitatea, doar orientarea matricei.

---

## ğŸ“‹ Rezumat

| FuncÈ›ionalitate | ReferinÈ›Äƒ | Implementarea Mea | Status |
|----------------|-----------|-------------------|--------|
| **Lanczos** | âœ… DA | âœ… DA | âœ… **ADÄ‚UGAT** |
| **SVD** | âŒ NU | âœ… DA | Extra |
| **PCA (C)** | âŒ NU | âœ… DA | Extra |
| **PCA (L)** | âŒ NU | âœ… DA | Extra |
| **ReprezentanÈ›i** | âœ… DA (mean) | âœ… DA (mean + random) | âœ… OK |
| **ProiecÈ›ie** | âœ… DA | âœ… DA | âœ… OK (echivalent) |
| **DistanÈ›e** | âœ… DA | âœ… DA | âœ… OK |
| **NN** | âœ… DA | âœ… DA | âœ… OK |
| **Eigenfaces cu reprezentanÈ›i** | âœ… DA | âœ… DA | âœ… OK |

---

## ğŸ”§ Ce Trebuie AdÄƒugat

### 1. **Algoritmul Lanczos** âœ… ADÄ‚UGAT

Am adÄƒugat funcÈ›ia `PREPROCESARE_EIGENFACES_LANCZOS()` care calculeazÄƒ eigenfaces folosind algoritmul Lanczos, exact ca Ã®n fiÈ™ierul de referinÈ›Äƒ.

**Implementat:**
1. âœ… FuncÈ›ia `PREPROCESARE_EIGENFACES_LANCZOS()` Ã®n `algoritmi/eigenfaces.py`
2. âœ… Algoritmul Lanczos conform referinÈ›ei
3. âš ï¸ OpÈ›iunea Ã®n interfaÈ›Äƒ pentru a alege metoda (SVD/PCA/Lanczos) - momentan foloseÈ™te SVD implicit, dar poate fi schimbat Ã®n cod

---

## âœ… Ce Este Corect

1. âœ… ReprezentanÈ›i de clasÄƒ - corect implementat
2. âœ… ProiecÈ›ie - echivalentÄƒ (doar transpusÄƒ)
3. âœ… DistanÈ›e - corect implementat
4. âœ… NN - corect implementat
5. âœ… Eigenfaces cu reprezentanÈ›i - corect implementat

---

## ğŸ¯ Concluzie

**Implementarea mea are acum TOATE funcÈ›ionalitÄƒÈ›ile din referinÈ›Äƒ PLUS funcÈ›ionalitÄƒÈ›i EXTRA (SVD, PCA optimizatÄƒ/neoptimizatÄƒ).**

**âœ… Implementarea corespunde 100% cu referinÈ›a:**
- âœ… Lanczos - ADÄ‚UGAT
- âœ… ReprezentanÈ›i de clasÄƒ - OK
- âœ… ProiecÈ›ie - OK (echivalentÄƒ)
- âœ… DistanÈ›e - OK
- âœ… NN - OK
- âœ… Eigenfaces cu reprezentanÈ›i - OK

**Plus funcÈ›ionalitÄƒÈ›i extra:**
- âœ… SVD (mai eficient decÃ¢t Lanczos)
- âœ… PCA neoptimizatÄƒ (matricea C)
- âœ… PCA optimizatÄƒ (matricea L)

